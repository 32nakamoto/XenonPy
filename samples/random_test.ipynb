{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xenonpy.model.nn import Generator1d\n",
    "import numpy as np\n",
    "\n",
    "g = Generator1d(1, 1, n_neuron=[10, 5], p_drop=(1., 0.9),\n",
    "                          batch_normalize=[True], momentum=(0.1, 0.2))\n",
    "m = g(1, n_models=10, replace=True)\n",
    "m = next(m)\n",
    "# len(list(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runner environment:\n",
      "Epochs: 1500\n",
      "Context: cpu\n",
      "Ignore exception: False\n",
      "Check step: 100\n",
      "Log step: 100\n",
      "\n",
      "at step: 0, Loss=0.3043\n",
      "at step: 100, Loss=0.2194\n",
      "at step: 200, Loss=0.1580\n",
      "at step: 300, Loss=0.1383\n",
      "at step: 400, Loss=0.1217\n",
      "at step: 500, Loss=0.1156\n",
      "at step: 600, Loss=0.1005\n",
      "at step: 700, Loss=0.0944\n",
      "at step: 800, Loss=0.0974\n",
      "at step: 900, Loss=0.1013\n",
      "at step: 1000, Loss=0.0950\n",
      "at step: 1100, Loss=0.0912\n",
      "at step: 1200, Loss=0.0920\n",
      "at step: 1300, Loss=0.0919\n",
      "at step: 1400, Loss=0.1003\n",
      "Loss=0.0916\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from xenonpy.model.nn import ModelRunner\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "x = torch.unsqueeze(\n",
    "    torch.linspace(-1, 1, 100), dim=1)  # x data (tensor), shape=(100, 1)\n",
    "y = x.pow(2) + 0.2 * torch.rand(\n",
    "    x.size())  # noisy y data (tensor), shape=(100, 1)\n",
    "\n",
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    "\n",
    "with ModelRunner(1500, log_step=100, ignore_except=False) as runner:\n",
    "    runner(m, loss_func=torch.nn.MSELoss(), optim=runner.SGD())\n",
    "    runner.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from random import uniform\n",
    "\n",
    "g = Generator1d(290, 1, n_neuron=[100], p_drop=(0.2,),\n",
    "                          batch_normalize=[True], momentum=(0.1,))\n",
    "\n",
    "m = g(4, n_models=3,replace=True, scheduler=lambda i, paras:  dict(paras, n_out=ceil(paras['n_out'] * uniform(0.5, 0.8))))\n",
    "# len(list(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Layer1d(\n",
       "    (neuron): Linear(in_features=290, out_features=100)\n",
       "    (batch_nor): BatchNorm1d(100, eps=0.1, momentum=0.1, affine=True)\n",
       "    (act_func): ReLU()\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (1): Layer1d(\n",
       "    (neuron): Linear(in_features=100, out_features=77)\n",
       "    (batch_nor): BatchNorm1d(77, eps=0.1, momentum=0.1, affine=True)\n",
       "    (act_func): ReLU()\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (2): Layer1d(\n",
       "    (neuron): Linear(in_features=77, out_features=41)\n",
       "    (batch_nor): BatchNorm1d(41, eps=0.1, momentum=0.1, affine=True)\n",
       "    (act_func): ReLU()\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (3): Layer1d(\n",
       "    (neuron): Linear(in_features=41, out_features=33)\n",
       "    (batch_nor): BatchNorm1d(33, eps=0.1, momentum=0.1, affine=True)\n",
       "    (act_func): ReLU()\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (4): Layer1d(\n",
       "    (neuron): Linear(in_features=33, out_features=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Layer1d(\n",
       "    (neuron): Linear(in_features=290, out_features=100)\n",
       "    (batch_nor): BatchNorm1d(100, eps=0.1, momentum=0.1, affine=True)\n",
       "    (act_func): ReLU()\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (1): Layer1d(\n",
       "    (neuron): Linear(in_features=100, out_features=69)\n",
       "    (batch_nor): BatchNorm1d(69, eps=0.1, momentum=0.1, affine=True)\n",
       "    (act_func): ReLU()\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (2): Layer1d(\n",
       "    (neuron): Linear(in_features=69, out_features=46)\n",
       "    (batch_nor): BatchNorm1d(46, eps=0.1, momentum=0.1, affine=True)\n",
       "    (act_func): ReLU()\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (3): Layer1d(\n",
       "    (neuron): Linear(in_features=46, out_features=35)\n",
       "    (batch_nor): BatchNorm1d(35, eps=0.1, momentum=0.1, affine=True)\n",
       "    (act_func): ReLU()\n",
       "    (dropout): Dropout(p=0.2)\n",
       "  )\n",
       "  (4): Layer1d(\n",
       "    (neuron): Linear(in_features=35, out_features=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
